{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filippozuddas/ML-SRT-SETI/blob/main/notebooks/train_CVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "TPoHtJa2I_E4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TPoHtJa2I_E4",
        "outputId": "22c096c8-c7a3-4812-ec07-a68be7dfc702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting setigen\n",
            "  Downloading setigen-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from setigen) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from setigen) (1.15.3)\n",
            "Requirement already satisfied: astropy>=5.0.4 in /usr/local/lib/python3.11/dist-packages (from setigen) (7.1.0)\n",
            "Collecting blimpy>=2.1.4 (from setigen)\n",
            "  Downloading blimpy-2.1.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from setigen) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from setigen) (4.67.1)\n",
            "Collecting sphinx-rtd-theme>=0.4.3 (from setigen)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting pytest-cov>=4.1.0 (from setigen)\n",
            "  Downloading pytest_cov-7.0.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.11/dist-packages (from astropy>=5.0.4->setigen) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.4.28.0.37.27 in /usr/local/lib/python3.11/dist-packages (from astropy>=5.0.4->setigen) (0.2025.6.23.0.39.50)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from astropy>=5.0.4->setigen) (6.0.2)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from astropy>=5.0.4->setigen) (24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from blimpy>=2.1.4->setigen) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from blimpy>=2.1.4->setigen) (75.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from blimpy>=2.1.4->setigen) (3.14.0)\n",
            "Collecting hdf5plugin (from blimpy>=2.1.4->setigen)\n",
            "  Downloading hdf5plugin-6.0.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from blimpy>=2.1.4->setigen) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from blimpy>=2.1.4->setigen) (11.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from blimpy>=2.1.4->setigen) (5.9.5)\n",
            "Collecting pyparsing==2.4.7 (from blimpy>=2.1.4->setigen)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->setigen) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->setigen) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->setigen) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->setigen) (1.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->setigen) (2.9.0.post0)\n",
            "Collecting coverage>=7.10.6 (from coverage[toml]>=7.10.6->pytest-cov>=4.1.0->setigen)\n",
            "  Downloading coverage-7.11.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: pluggy>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytest-cov>=4.1.0->setigen) (1.6.0)\n",
            "Requirement already satisfied: pytest>=7 in /usr/local/lib/python3.11/dist-packages (from pytest-cov>=4.1.0->setigen) (8.3.5)\n",
            "Requirement already satisfied: sphinx<9,>=6 in /usr/local/lib/python3.11/dist-packages (from sphinx-rtd-theme>=0.4.3->setigen) (8.2.3)\n",
            "Requirement already satisfied: docutils<0.22,>0.18 in /usr/local/lib/python3.11/dist-packages (from sphinx-rtd-theme>=0.4.3->setigen) (0.21.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme>=0.4.3->setigen)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=7->pytest-cov>=4.1.0->setigen) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.19.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.32.3)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->blimpy>=2.1.4->setigen) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->blimpy>=2.1.4->setigen) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx<9,>=6->sphinx-rtd-theme>=0.4.3->setigen) (2025.6.15)\n",
            "Downloading setigen-2.7.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blimpy-2.1.4-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_cov-7.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coverage-7.11.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (249 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m249.3/249.3 kB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hdf5plugin-6.0.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (44.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.9/44.9 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyparsing, coverage, hdf5plugin, sphinxcontrib-jquery, pytest-cov, blimpy, sphinx-rtd-theme, setigen\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydot 3.0.4 requires pyparsing>=3.0.9, but you have pyparsing 2.4.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blimpy-2.1.4 coverage-7.11.3 hdf5plugin-6.0.0 pyparsing-2.4.7 pytest-cov-7.0.0 setigen-2.7.0 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "14f022560c0f40b39d44ca6f845cc958",
              "pip_warning": {
                "packages": [
                  "pyparsing",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install setigen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "vVtKbNZ0Jc_9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVtKbNZ0Jc_9",
        "outputId": "11117107-0efa-4c86-c72d-73af2af94505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Setup completed!\n",
            "   Working directory: /home/filippo/TirocinioSETI/ML-SRT-SETI\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# --- CONFIGURAZIONE PERCORSI ---\n",
        "PROJECT_ROOT = \"/content/filippo/ML-SRT-SETI\"\n",
        "PROJECT_ROOT_LOCAL = \"/home/filippo/TirocinioSETI/ML-SRT-SETI\"\n",
        "\n",
        "if not os.path.exists(PROJECT_ROOT_LOCAL):\n",
        "    raise FileNotFoundError(f\"{PROJECT_ROOT_LOCAL} folder not found\")\n",
        "\n",
        "os.chdir(PROJECT_ROOT_LOCAL)\n",
        "\n",
        "if PROJECT_ROOT_LOCAL not in sys.path:\n",
        "    sys.path.append(PROJECT_ROOT_LOCAL)\n",
        "\n",
        "print(f\"âœ… Setup completed!\")\n",
        "print(f\"   Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2b29dcf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b29dcf9",
        "outputId": "755c310d-500f-43d8-c034-84cfdbbfb395"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 17:14:16.106203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-11-17 17:14:16.650519: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-17 17:14:16.724509: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2025-11-17 17:14:16.724620: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2025-11-17 17:14:16.825603: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-11-17 17:14:18.836140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2025-11-17 17:14:18.836466: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2025-11-17 17:14:18.836485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/home/filippo/miniconda3/envs/ml_gbt_seti/lib/python3.9/site-packages/blimpy/__init__.py:21: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import get_distribution, DistributionNotFound\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.10.1\n",
            "Num GPUs Available:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 17:14:23.898686: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2025-11-17 17:14:23.899283: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (filippo-ideapad-slim-5): /proc/driver/nvidia/version does not exist\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from src import config, models\n",
        "\n",
        "# Verifica GPU\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f61e6897",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from src.generator import SetigenGenerator\n",
        "from src.models import VAE\n",
        "\n",
        "# --- CONFIGURAZIONE ---\n",
        "# Hardware & Percorsi\n",
        "GPUS = tf.config.list_physical_devices('GPU')\n",
        "LOG_DIR = \"logs\"\n",
        "CHECKPOINT_DIR = \"checkpoints\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Iperparametri\n",
        "# Batch size globale: con 2x4090 possiamo spingere.\n",
        "# Inizia con 64 o 128. Se hai OOM (Out of Memory), riduci.\n",
        "BATCH_SIZE_PER_REPLICA = 64 \n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * len(GPUS) if len(GPUS) > 0 else BATCH_SIZE_PER_REPLICA\n",
        "\n",
        "EPOCHS = 100\n",
        "STEPS_PER_EPOCH = 1000  # Quanti batch processare per considerare finita un'epoca\n",
        "LEARNING_RATE = 1e-4    # Tasso di apprendimento iniziale (Paper: 0.0005)\n",
        "LATENT_DIM = 8          # Dimensione spazio latente (Paper: 8)\n",
        "\n",
        "# Parametri Generatore (Simulazione)\n",
        "SNR_RANGE = (10, 50)\n",
        "DRIFT_RANGE = (0.5, 8.0)\n",
        "\n",
        "def main():\n",
        "    print(f\"ðŸš€ Avvio Training SETI VAE\")\n",
        "    print(f\"Num GPUs Available: {len(GPUS)}\")\n",
        "    print(f\"Global Batch Size: {GLOBAL_BATCH_SIZE}\")\n",
        "    \n",
        "    # 1. Setup Strategia Multi-GPU\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(f'Number of devices: {strategy.num_replicas_in_sync}')\n",
        "\n",
        "    # 2. Preparazione Dati\n",
        "    # Creiamo due generatori: uno per training e uno per validation\n",
        "    # (Nota: essendo dati sintetici, la validation serve a controllare che la loss scenda su dati nuovi)\n",
        "    \n",
        "    train_gen = SetigenGenerator(\n",
        "        batch_size=GLOBAL_BATCH_SIZE,\n",
        "        snr_range=SNR_RANGE,\n",
        "        drift_range=DRIFT_RANGE\n",
        "    )\n",
        "    train_dataset = train_gen.get_dataset()\n",
        "\n",
        "    # Dataset di Validazione (Separiamo per monitorare l'overfitting)\n",
        "    val_gen = SetigenGenerator(\n",
        "        batch_size=GLOBAL_BATCH_SIZE,\n",
        "        snr_range=SNR_RANGE, \n",
        "        drift_range=DRIFT_RANGE\n",
        "    )\n",
        "    val_dataset = val_gen.get_dataset()\n",
        "\n",
        "    # 3. Costruzione Modello nello Scope della Strategia\n",
        "    with strategy.scope():\n",
        "        # Istanziamo il modello VAE\n",
        "        # Input shape: (6, 16, 512, 1) - La cadenza intera\n",
        "        vae = SETI_VAE(\n",
        "            input_shape=(6, 16, 512, 1),\n",
        "            latent_dim=LATENT_DIM,\n",
        "            beta=1.5,  # Peso KL\n",
        "            alpha=10.0 # Peso Clustering\n",
        "        )\n",
        "        \n",
        "        # Compiliamo il modello\n",
        "        # Non passiamo una loss function qui perchÃ© Ã¨ gestita internamente nel train_step del modello custom\n",
        "        vae.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
        "\n",
        "    # 4. Callbacks\n",
        "    # Nome univoco per il run\n",
        "    run_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    \n",
        "    # Salva i pesi migliori\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"vae_seti_{run_name}_best.h5\")\n",
        "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_path,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True, # Salviamo solo i pesi per flessibilitÃ  (custom model)\n",
        "        monitor='val_total_loss', # Monitoriamo la loss totale validazione\n",
        "        mode='min',\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # Log CSV per grafici\n",
        "    csv_logger = keras.callbacks.CSVLogger(os.path.join(LOG_DIR, f\"training_log_{run_name}.csv\"))\n",
        "    \n",
        "    # Riduzione LR se ci blocchiamo\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_total_loss', \n",
        "        factor=0.5, \n",
        "        patience=5, \n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Early Stopping\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_total_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 5. Avvio Training\n",
        "    print(\"\\nDataset e Modello pronti. Inizio fit()...\")\n",
        "    \n",
        "    history = vae.fit(\n",
        "        train_dataset,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=STEPS_PER_EPOCH,\n",
        "        validation_data=val_dataset,\n",
        "        validation_steps=100, # 100 batch di validazione\n",
        "        callbacks=[checkpoint_cb, csv_logger, reduce_lr, early_stop]\n",
        "    )\n",
        "\n",
        "    print(\"âœ… Training completato.\")\n",
        "    \n",
        "    # Salvataggio finale (modello completo se possibile, o pesi)\n",
        "    final_save_path = os.path.join(CHECKPOINT_DIR, f\"vae_seti_{run_name}_final_weights.h5\")\n",
        "    vae.save_weights(final_save_path)\n",
        "    print(f\"Pesi finali salvati in: {final_save_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_gbt_seti",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
