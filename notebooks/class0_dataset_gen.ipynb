{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8ed615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root aggiunta al path: /home/filippo/TirocinioSETI/ML-SRT-SETI\n",
      "Inizio generazione di 5000 campioni di Classe 0 (Rumore/RFI)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:56<00:00, 28.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generazione completata. Shape finale: (5000, 6, 16, 512, 1)\n",
      "Salvataggio in ../data/processed/train_class0_5k.npy...\n",
      "Fatto! Dataset pronto per il training.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm # Barra di caricamento\n",
    "import sys\n",
    "\n",
    "# Ottieni il percorso assoluto della cartella genitore (la root del progetto)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Aggiungilo al path di Python se non c'è già\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Verifica (opzionale)\n",
    "print(f\"Project Root aggiunta al path: {project_root}\")\n",
    "\n",
    "from src import config, generation\n",
    "\n",
    "# Configurazione Dataset\n",
    "N_SAMPLES_TRAIN = 5000  # Nel paper usano di più, ma per testare 5k vanno bene\n",
    "OUTPUT_FILE = \"../data/processed/train_class0_5k.npy\"\n",
    "\n",
    "# Assicuriamoci che la cartella esista\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "print(f\"Inizio generazione di {N_SAMPLES_TRAIN} campioni di Classe 0 (Rumore/RFI)...\")\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for _ in tqdm(range(N_SAMPLES_TRAIN)):\n",
    "    # Generiamo solo Classe 0 perché l'Autoencoder si addestra solo su questo\n",
    "    data, _ = generation.create_false_sample()\n",
    "    \n",
    "    # data ha shape (6, 16, 512, 1). \n",
    "    # Il VAE lavora su singoli frame o sulla sequenza? \n",
    "    # Nel paper, l'Encoder processa i frame 16x512 INDIPENDENTEMENTE.\n",
    "    # Quindi possiamo salvare i dati come (N_SAMPLES * 6, 16, 512, 1)\n",
    "    # oppure mantenerli divisi per cadenza. \n",
    "    # Manteniamoli (6, 16, 512, 1) per flessibilità futura.\n",
    "    data_list.append(data)\n",
    "\n",
    "# Convertiamo in numpy array\n",
    "full_dataset = np.array(data_list)\n",
    "\n",
    "print(f\"Generazione completata. Shape finale: {full_dataset.shape}\")\n",
    "print(f\"Salvataggio in {OUTPUT_FILE}...\")\n",
    "\n",
    "np.save(OUTPUT_FILE, full_dataset)\n",
    "\n",
    "print(\"Fatto! Dataset pronto per il training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_gbt_seti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
